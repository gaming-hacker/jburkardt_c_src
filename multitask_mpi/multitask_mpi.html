<html>

  <head>
    <title>
      MULTITASK_MPI - Carrying Out Multiple "Tasks" in MPI
    </title>
  </head>

  <body bgcolor="#EEEEEE" link="#CC0000" alink="#FF3300" vlink="#000055">

    <h1 align = "center">
      MULTITASK_MPI <br> Carrying Out Multiple "Tasks" in MPI
    </h1>

    <hr>

    <p>
      <b>MULTITASK_MPI</b>,
      a C code which
      demonstrates how to "multitask", that is, to execute several unrelated
      and distinct tasks simultaneously, using MPI for parallel execution.
    </p>

    <p>
      In this example, there is a "master" process, identified as process 0,
      and two worker processes, 1 and 2.  Process 0 does nothing but choose the
      input for the worker processes, transmit it, and wait for the computed
      results to be returned.  The codes executed by process 1 and by process 2
      are quite different.
    </p>

    <p>
      While the typical MPI model has all the worker processes executing the
      same code, this example shows that that is not necessary.
    </p>

    <h3 align = "center">
      Licensing:
    </h3>

    <p>
      The computer code and data files made available on this web page 
      are distributed under
      <a href = "https://www.gnu.org/licenses/lgpl-3.0.en.html">the GNU LGPL license.</a>
    </p>

    <h3 align = "center">
      Languages:
    </h3>

    <p>
      <b>MULTITASK_MPI</b> is available in
      <a href = "../../c_src/multitask_mpi/multitask_mpi.html">a C version</a> and
      <a href = "../../cpp_src/multitask_mpi/multitask_mpi.html">a C++ version</a> and
      <a href = "../../f_src/multitask_mpi/multitask_mpi.html">a FORTRAN90 version</a>.
    </p>

    <h3 align = "center">
      Related Data and codes:
    </h3>

    <p>
      <a href = "../../c_src/communicator_mpi/communicator_mpi.html">
      COMMUNICATOR_MPI</a>,
      a C code which
      creates new communicators involving a subset of initial
      set of MPI processes in the default communicator MPI_COMM_WORLD.
    </p>

    <p>
      <a href = "../../c_src/heat_mpi/heat_mpi.html">
      HEAT_MPI</a>,
      a C code which 
      solves the 1D Time Dependent Heat Equation using MPI.
    </p>

    <p>
      <a href = "../../c_src/hello_mpi/hello_mpi.html">
      HELLO_MPI</a>,
      a C code which 
      prints out "Hello, world!" using the MPI parallel codeming environment. 
    </p>

    <p>
      <a href = "../../c_src/laplace_mpi/laplace_mpi.html">
      LAPLACE_MPI</a>,
      a C code which
      solves Laplace's equation on a rectangle,
      using MPI for parallel execution.
    </p>

    <p>
      <a href = "../../c_src/mpi_test/mpi_test.html">
      mpi_test</a>,
      C codes which
      illustrate the use of the MPI application code interface
      for carrying out parallel computatioins in a distributed memory environment.
    </p>

    <p>
      <a href = "../../c_src/multitask_mpi_test/multitask_mpi_test.html">
      multitask_mpi_test</a>
    </p>

    <p>
      <a href = "../../c_src/multitask_openmp/multitask_openmp.html">
      MULTITASK_OPENMP</a>,
      a C code which
      demonstrates how to "multitask", that is, to execute several unrelated
      and distinct tasks simultaneously, using OpenMP for parallel execution.
    </p>

    <p>
      <a href = "../../c_src/poisson_mpi/poisson_mpi.html">
      POISSON_MPI</a>,
      a C code which
      computes a solution to the Poisson equation in a rectangle,
      using the Jacobi iteration to solve the linear system, and MPI to
      carry out the Jacobi iteration in parallel.
    </p>

    <p>
      <a href = "../../c_src/prime_mpi/prime_mpi.html">
      PRIME_MPI</a>,
      a C code which
      counts the number of primes between 1 and N, using MPI for parallel execution.
    </p>

    <p>
      <a href = "../../c_src/quad_mpi/quad_mpi.html">
      QUAD_MPI</a>,
      a C code which
      approximates an integral using a quadrature rule, and carries out the
      computation in parallel using MPI.
    </p>

    <p>
      <a href = "../../c_src/random_mpi/random_mpi.html">
      RANDOM_MPI</a>,
      a C code which
      demonstrates one way to generate the same sequence of random numbers
      for both sequential execution and parallel execution under MPI.
    </p>

    <p>
      <a href = "../../c_src/ring_mpi/ring_mpi.html">
      RING_MPI</a>,
      a C code which
      uses the MPI parallel codeming environment, and measures the time
      necessary to copy a set of data around a ring of processes.
    </p>

    <p>
      <a href = "../../c_src/satisfy_mpi/satisfy_mpi.html">
      SATISFY_MPI</a>,
      a C code which 
      demonstrates, for a particular circuit, an exhaustive search
      for solutions of the circuit satisfiability problem, using MPI to
      carry out the calculation in parallel.
    </p>

    <p>
      <a href = "../../c_src/search_mpi/search_mpi.html">
      SEARCH_MPI</a>,
      a C code which
      searches integers between A and B for a value J such that F(J) = C,
      using MPI.
    </p>

    <p>
      <a href = "../../c_src/wave_mpi/wave_mpi.html">
      WAVE_MPI</a>,
      a C code which
      uses finite differences and MPI to estimate a solution to the
      wave equation.
    </p>

    <h3 align = "center">
      Reference:
    </h3>

    <p>
      <ol>
        <li>
          William Gropp, Steven Huss-Lederman, Andrew Lumsdaine, Ewing Lusk,
          Bill Nitzberg, 
          William Saphir, Marc Snir,<br>
          MPI: The Complete Reference,<br>
          Volume II: The MPI-2 Extensions,<br>
          Second Edition,<br>
          MIT Press, 1998.
        </li>
        <li>
          William Gropp, Ewing Lusk, Anthony Skjellum,<br>
          Using MPI: Portable Parallel codeming with the
          Message-Passing Interface,<br>
          Second Edition,<br>
          MIT Press, 1999,<br>
          ISBN: 0262571323.
        </li>
        <li>
          William Gropp, Ewing Lusk, Rajiv Thakur,<br>
          Using MPI-2: Advanced Features of the Message-Passing
          Interface,<br>
          Second Edition,<br>
          MIT Press, 1999,<br>
          ISBN: 0262571331.
        </li>
        <li>
          Stan Openshaw, Ian Turton,<br>
          High Performance Computing and the Art of Parallel codeming: 
          an Introduction for Geographers, Social Scientists, and
          Engineers,<br>
          Routledge, 2000,<br>
          ISBN: 0415156920.
        </li>
        <li>
          Peter Pacheco,<br>
          Parallel codeming with MPI,<br>
          Morgan Kaufman, 1996,<br>
          ISBN: 1558603395,<br>
          LC: QA76.642.P3.
        </li>
        <li>
          Marc Snir, Steve Otto, Steven Huss-Lederman, David Walker, 
          Jack Dongarra,<br>
          MPI: The Complete Reference,<br>
          Volume I: The MPI Core,<br>
          Second Edition,<br>
          MIT Press, 1998,<br>
          ISBN: 0-262-69216-3,<br>
          LC: QA76.642.M65.
        </li>
        <li>
          The Message Passing Interface Forum,<br>
          <b>MPI: A Message Passing Interface Standard</B>,<br>
          1995.
        </li>
        <li>
          The Message Passing Interface Forum,<br>
          <b>MPI-2: Extensions to the Message Passing Interface</B>,<br>
          1997.
        </li>
      </ol>
    </p>

    <h3 align = "center">
      Source Code:
    </h3>

    <p>
      <ul>
        <li>
          <a href = "multitask_mpi.c">multitask_mpi.c</a>, the source code.
        </li>
        <li>
          <a href = "multitask_mpi.sh">multitask_mpi.sh</a>,
          compiles the source code.
        </li>
      </ul>
    </p>

    <hr>

    <i>
      Last revised on 25 June 2020.
    </i>

    <!-- John Burkardt -->

  </body>

  <!-- Initial HTML skeleton created by HTMLINDEX. -->

</html>
