<html>

  <head>
    <title>
      RANDOM_MPI - Random Numbers using MPI
    </title>
  </head>

  <body bgcolor="#EEEEEE" link="#CC0000" alink="#FF3300" vlink="#000055">

    <h1 align = "center">
      RANDOM_MPI <br> Random Numbers using MPI
    </h1>

    <hr>

    <p>
      <b>RANDOM_MPI</b>,
      a C code which 
      generates the same sequence of random numbers
      for both sequential execution and parallel execution under MPI.
    </p>

    <p>
      A simpler approach to random numbers would simply let each processor
      choose a seed.  Or the master processor could choose distinct seeds.
      However, this is not ideal since it will not match the sequential code
      and it does not avoid the possibility that two of the random sequences
      will quickly overlap because of a bad choice of seed.
    </p>

    <p>
      Notice that if we have 10 processors available under MPI, we do not
      want each processor to generate the same random number sequence.
      Instead, we want each of the processors to generate a part of the
      sequence, so that all the parts together make up the same set of values
      that a sequential code would have computed.
    </p>

    <p>
      We assume we are using a linear congruential
      random number generator or "LCRG", which takes
      an integer input and returns a new integer output:
      <blockquote><b>
          U = ( A * V + B ) mod C
      </b></blockquote>
      We assume that we want the MPI code to produce
      the same sequence of random values as a sequential
      code would - but we want each processor to compute
      one part of that sequence.
    </p>

    <p>
      We do this by computing a new LCRG which can compute
      every P'th entry of the original one.
    </p>

    <p>
      Our LCRG works with integers, but it is easy to
      turn each integer into a real number between [0,1].
    </p>

    <p>
      The particular scheme for computing the parameters of the new LCRG
      is implemented in the <b>UNIFORM</b> library.
    </p>

    <h3 align = "center">
      Licensing:
    </h3>

    <p>
      The computer code and data files made available on this web page 
      are distributed under
      <a href = "https://www.gnu.org/licenses/lgpl-3.0.en.html">the GNU LGPL license.</a>
    </p>

    <h3 align = "center">
      Languages:
    </h3>

    <p>
      <b>RANDOM_MPI</b> is available in
      <a href = "../../c_src/random_mpi/random_mpi.html">a C version</a> and
      <a href = "../../cpp_src/random_mpi/random_mpi.html">a C++ version</a> and
      <a href = "../../f_src/random_mpi/random_mpi.html">a FORTRAN90 version.</a>
    </p>

    <h3 align = "center">
      Related Data and codes:
    </h3>

    <p>
      <a href = "../../c_src/communicator_mpi/communicator_mpi.html">
      COMMUNICATOR_MPI</a>,
      a C code which
      creates new communicators involving a subset of initial
      set of MPI processes in the default communicator MPI_COMM_WORLD.
    </p>

    <p>
      <a href = "../../c_src/heat_mpi/heat_mpi.html">
      HEAT_MPI</a>,
      a C code which 
      solves the 1D Time Dependent Heat Equation using MPI.
    </p>

    <p>
      <a href = "../../c_src/hello_mpi/hello_mpi.html">
      HELLO_MPI</a>,
      a C code which 
      prints out "Hello, world!" using the MPI parallel codeming environment. 
    </p>

    <p>
      <a href = "../../c_src/laplace_mpi/laplace_mpi.html">
      LAPLACE_MPI</a>,
      a C code which
      solves Laplace's equation on a rectangle,
      using MPI for parallel execution.
    </p>

    <p>
      <a href = "../../c_src/mpi_test/mpi_test.html">
      mpi_test</a>,
      C codes which
      illustrate the use of the MPI application code interface
      for carrying out parallel computatioins in a distributed memory environment.
    </p>

    <p>
      <a href = "../../c_src/multitask_mpi/multitask_mpi.html">
      MULTITASK_MPI</a>,
      a C code which
      demonstrates how to "multitask", that is, to execute several unrelated
      and distinct tasks simultaneously, using MPI for parallel execution.
    </p>

    <p>
      <a href = "../../c_src/poisson_mpi/poisson_mpi.html">
      POISSON_MPI</a>,
      a C code which
      computes a solution to the Poisson equation in a rectangle,
      using the Jacobi iteration to solve the linear system, and MPI to
      carry out the Jacobi iteration in parallel.
    </p>

    <p>
      <a href = "../../c_src/prime_mpi/prime_mpi.html">
      PRIME_MPI</a>,
      a C code which
      counts the number of primes between 1 and N, using MPI for parallel execution.
    </p>

    <p>
      <a href = "../../c_src/quad_mpi/quad_mpi.html">
      QUAD_MPI</a>,
      a C code which
      approximates an integral using a quadrature rule, and carries out the
      computation in parallel using MPI.
    </p>

    <p>
      <a href = "../../c_src/random_mpi_test/random_mpi_test.html">
      random_mpi_test</a>
    </p>

    <p>
      <a href = "../../c_src/ring_mpi/ring_mpi.html">
      RING_MPI</a>,
      a C code which
      uses the MPI parallel codeming environment, and measures the time
      necessary to copy a set of data around a ring of processes.
    </p>

    <p>
      <a href = "../../c_src/satisfy_mpi/satisfy_mpi.html">
      SATISFY_MPI</a>,
      a C code which 
      demonstrates, for a particular circuit, an exhaustive search
      for solutions of the circuit satisfiability problem, using MPI to
      carry out the calculation in parallel.
    </p>

    <p>
      <a href = "../../c_src/search_mpi/search_mpi.html">
      SEARCH_MPI</a>,
      a C code which
      searches integers between A and B for a value J such that F(J) = C,
      using MPI.
    </p>

    <p>
      <a href = "../../c_src/wave_mpi/wave_mpi.html">
      WAVE_MPI</a>,
      a C code which
      uses finite differences and MPI to estimate a solution to the
      wave equation.
    </p>

    <h3 align = "center">
      Reference:
    </h3>

    <p>
      <ol>
        <li>
          Peter Arbenz, Wesley Petersen,<br>
          Introduction to Parallel Computing - 
          A practical guide with examples in C,<br>
          Oxford University Press,<br>
          ISBN: 0-19-851576-6,<br>
          LC: QA76.58.P47.
        </li>
        <li>
          Stan Openshaw, Ian Turton,<br>
          High Performance Computing and the Art of Parallel codeming: 
          an Introduction for Geographers, Social Scientists, and
          Engineers,<br>
          Routledge, 2000,<br>
          ISBN: 0415156920.
        </li>
        <li>
          Peter Pacheco,<br>
          Parallel codeming with MPI,<br>
          Morgan Kaufman, 1996,<br>
          ISBN: 1558603395,<br>
          LC: QA76.642.P3.
        </li>
        <li>
          Michael Quinn,<br>
          Parallel codeming in C with MPI and OpenMP,<br>
          McGraw-Hill, 2004,<br>
          ISBN13: 978-0071232654,<br>
          LC: QA76.73.C15.Q55.
        </li>
      </ol>
    </p>

    <h3 align = "center">
      Source Code:
    </h3>

    <p>
      <ul>
        <li>
          <a href = "random_mpi.c">random_mpi.c</a>, the source code.
        </li>
        <li>
          <a href = "random_mpi.sh">random_mpi.sh</a>,
          compiles the source code.
        </li>
      </ul>
    </p>

    <hr>

    <i>
      Last revised on 26 June 2020.
    </i>

    <!-- John Burkardt -->

  </body>

  <!-- Initial HTML skeleton created by HTMLINDEX. -->

</html>
